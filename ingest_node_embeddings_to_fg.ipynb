{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Model Repository for best node embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import model\n",
    "from hops.model import Metric\n",
    "MODEL_NAME=\"NodeEmbeddings\"\n",
    "EVALUATION_METRIC=\"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.get_best_model(MODEL_NAME, EVALUATION_METRIC, Metric.MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: NodeEmbeddings\n",
      "Model version: 1\n",
      "{'accuracy': '0.6678586006164551'}"
     ]
    }
   ],
   "source": [
    "print('Model name: ' + best_model['name'])\n",
    "print('Model version: ' + str(best_model['version']))\n",
    "print(best_model['metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Serving of Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NodeEmbeddings'"
     ]
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a serving for model NodeEmbeddings ...\n",
      "Serving for model NodeEmbeddings successfully created"
     ]
    }
   ],
   "source": [
    "# Create serving\n",
    "model_path=\"/Models/\" + best_model['name']\n",
    "model_path\n",
    "response = serving.create_or_update(artifact_path=model_path, serving_name=MODEL_NAME, serving_type=\"TENSORFLOW\", \n",
    "                                 model_version=best_model['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeEmbeddings"
     ]
    }
   ],
   "source": [
    "# List all available servings in the project\n",
    "for s in serving.get_all():\n",
    "    print(s.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Running'"
     ]
    }
   ],
   "source": [
    "# Get serving status\n",
    "serving.get_status(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Model Serving Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if serving.get_status(MODEL_NAME) == 'Stopped':\n",
    "    serving.start(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while serving.get_status(MODEL_NAME) != \"Running\":\n",
    "    time.sleep(5) # Let the serving startup correctly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Prediction Requests to the Served Model using Hopsworks REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras  \n",
    "\n",
    "import pandas as pd\n",
    "from stellargraph import StellarDiGraph\n",
    "from stellargraph.mapper import Node2VecLinkGenerator, Node2VecNodeGenerator\n",
    "from stellargraph.data import UnsupervisedSampler, BiasedRandomWalk\n",
    "from stellargraph.layer import Node2Vec\n",
    "import pydoop.hdfs as pydoop\n",
    "import hsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully."
     ]
    }
   ],
   "source": [
    "# Create a connection\n",
    "connection = hsfs.connection()\n",
    "# Get the feature store handle for the project's feature store\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_td = fs.get_training_dataset(\"node_td\", 1)\n",
    "edge_td = fs.get_training_dataset(\"edges_td\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fg as pandas\n",
    "node_pdf = node_td.read().toPandas()\n",
    "edge_pdf = edge_td.read().drop(\"tran_timestamp\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining StellarDiGraph"
     ]
    }
   ],
   "source": [
    "node_data = pd.DataFrame(node_pdf[['tx_behavior_id','prior_sar','initial_deposit']], index=node_pdf['id'])\n",
    "\n",
    "print('Defining StellarDiGraph')\n",
    "G =StellarDiGraph(node_data,\n",
    "                      edges=edge_pdf, \n",
    "                      edge_type_column=\"tx_type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_number = 2\n",
    "walk_length = 2\n",
    "batch_size = 1\n",
    "emb_size = 16\n",
    "# Extracting node embeddings\n",
    "walker = BiasedRandomWalk(\n",
    "        G,\n",
    "        n=walk_number,\n",
    "        length=walk_length,\n",
    "        p=0.5,  # defines probability, 1/p, of returning to source node\n",
    "        q=2.0,  # defines probability, 1/q, for moving to a node away from the source node\n",
    "    )\n",
    "unsupervised_samples = UnsupervisedSampler(G, nodes=list(G.nodes()), walker=walker)\n",
    "generator = Node2VecLinkGenerator(G, batch_size)\n",
    "\n",
    "node2vec = Node2Vec(emb_size, generator=generator)\n",
    "x_inp, x_out = node2vec.in_out_tensors()\n",
    "\n",
    "x_inp_src = x_inp[0]\n",
    "x_out_src = x_out[0]\n",
    "embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_model.load_weights(pydoop.path.abspath(\"hdfs:///Projects/amlsim2/Models/NodeEmbeddings/1/variables\"))\n",
    "loaded_model = tf.keras.models.load_model(pydoop.path.abspath(\"hdfs:///Projects/amlsim2/Models/node_embeddings/1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes())\n",
    "node_gen = Node2VecNodeGenerator(G, batch_size).flow(nodes)\n",
    "#node_embeddings = loaded_model.predict(node_gen)\n",
    "#node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.functional.Functional object at 0x7fef23a89810>"
     ]
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"class_name\": \"Functional\", \"config\": {\"name\": \"functional_1\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_1\"}, \"name\": \"input_1\", \"inbound_nodes\": []}, {\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_2\"}, \"name\": \"input_2\", \"inbound_nodes\": []}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"target_embedding\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"input_dim\": 9998, \"output_dim\": 16, \"embeddings_initializer\": {\"class_name\": \"RandomUniform\", \"config\": {\"minval\": -1.0, \"maxval\": 1.0, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false, \"input_length\": 1}, \"name\": \"target_embedding\", \"inbound_nodes\": [[[\"input_1\", 0, 0, {}]]]}, {\"class_name\": \"Embedding\", \"config\": {\"name\": \"context_embedding\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"input_dim\": 9998, \"output_dim\": 16, \"embeddings_initializer\": {\"class_name\": \"TruncatedNormal\", \"config\": {\"mean\": 0.0, \"stddev\": 0.25, \"seed\": null}}, \"embeddings_regularizer\": null, \"activity_regularizer\": null, \"embeddings_constraint\": null, \"mask_zero\": false, \"input_length\": 1}, \"name\": \"context_embedding\", \"inbound_nodes\": [[[\"input_2\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [16]}, \"name\": \"reshape\", \"inbound_nodes\": [[[\"target_embedding\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_1\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [16]}, \"name\": \"reshape_1\", \"inbound_nodes\": [[[\"context_embedding\", 0, 0, {}]]]}, {\"class_name\": \"LinkEmbedding\", \"config\": {\"name\": \"link_embedding\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"linear\", \"method\": \"dot\", \"axis\": -2}, \"name\": \"link_embedding\", \"inbound_nodes\": [[[\"reshape\", 0, 0, {}], [\"reshape_1\", 0, 0, {}]]]}, {\"class_name\": \"Activation\", \"config\": {\"name\": \"activation\", \"trainable\": true, \"dtype\": \"float32\", \"activation\": \"sigmoid\"}, \"name\": \"activation\", \"inbound_nodes\": [[[\"link_embedding\", 0, 0, {}]]]}, {\"class_name\": \"Reshape\", \"config\": {\"name\": \"reshape_2\", \"trainable\": true, \"dtype\": \"float32\", \"target_shape\": [1]}, \"name\": \"reshape_2\", \"inbound_nodes\": [[[\"activation\", 0, 0, {}]]]}], \"input_layers\": [[\"input_1\", 0, 0], [\"input_2\", 0, 0]], \"output_layers\": [[\"reshape_2\", 0, 0]]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
     ]
    }
   ],
   "source": [
    "loaded_model.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1], dtype=uint16), None)"
     ]
    }
   ],
   "source": [
    "node_gen.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
